\documentclass{rapport}
\usepackage[utf8]{inputenc}

\usepackage{pifont} % Pour les symboles appelés par la macro \ding
\usepackage{url} % Comme son nom l'indique, pour les url...

\usetikzlibrary{positioning} % Bibliothèque tikz pour positionner des nœuds relativement à d'autres

\usepackage[colorlinks, citecolor=red!60!green, linkcolor=blue!60!green, urlcolor=magenta]{hyperref} % Pour que les liens soient cliquables. Les options permettent de mettre les liens en couleur.

\usepackage{algorithm}
\usepackage{algo}
\usepackage{colorationSyntaxique}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{float}


% Pour un rapport en français 
% \usepackage[francais]{babel} % Commenter pour un rapport en anglais
% \renewcommand\bibsection{\section*{Bibliographie}} % Commenter pour un rapport en anglais

\englishTitlePage % Décommenter pour une page de titre en anglais


\pagestyle{fancy}
\renewcommand{\sectionmark}[1]{\markboth{\thesection.\ #1}{}}
\fancyfoot{}

\newcommand{\gcc}{\texttt{gcc} }
\newcommand{\icx}{\texttt{icx} }
\newcommand{\clang}{\texttt{clang} }
\newcommand{\comp}{\texttt{ccomp} }
\newcommand{\optizero}{\texttt{-O0} }
\newcommand{\optione}{\texttt{-O1} }
\newcommand{\optitwo}{\texttt{-O2} }
\newcommand{\optithree}{\texttt{-O3} }
\newcommand{\optisize}{\texttt{-Os} }

\fancyhead[LE]{\textsl{\leftmark}}
\fancyhead[RE, LO]{\textbf{\thepage}}
\fancyhead[RO]{\textsl{\rightmark}}

\def\Latex{\LaTeX\xspace}
\def\etc{\textit{etc.}\xspace}

\lstset{                  % Specify language
basicstyle=\ttfamily\small,     % Code font and size
keywordstyle=\color{blue},      % Color for keywords
commentstyle=\color{gray},      % Color for comments
stringstyle=\color{red},        % Color for strings
numbers=left,                   % Add line numbers
numberstyle=\tiny\color{gray},  % Style for line numbers
% frame=single,                   % Add a border around code
breaklines=true,                % Line wrapping
% backgroundcolor=\color{gray!10} % Light gray background
}


\title{Optimizing application performance through optimizing compilation}
\author{Francois Flandin}
\supervisor{Pr Sid Touati}
\date{First semester of year 2024-2025}

% \universityname{Université Côte d'Azur} % Nom de l'université.
% \type{TER} % Type de document
% \formation{Master Informatique} % Nom de la formation

% Retrouver les autres options possibles dans le document rapport.pdf

\begin{document}

\maketitle


\clearpage
\tableofcontents

\clearpage
\section{Introduction}
The tutoring project titled "Optimizing Application Performance through Compilation Optimization" explores how compilers improve the generated code 
using various optimization levels: \optizero, \optione, \optitwo, \optithree, and \optisize. \newline
The different optimization levels goes from \optizero, which means no optimization, to \optithree, which enables the most optimizations, but also \optisize, which
compiles to have the most compact code.\newline
This project is divided into two main phases:
\begin{itemize}
    \item Experimentation: Compile two programs with four different compilers (\gcc, \icx, \clang, and \comp) at each optimization level, 
    measure execution times over 12 iterations, and plot the data using \texttt{R}.
    \item Optimization Analysis: Study the optimization options enabled by each compiler at each level, to better understand their internal mechanisms.
\end{itemize}
These steps allow for the evaluation of compilers not only in terms of speed but also by identifying the specific characteristics of each optimization level.

\clearpage

\part{The experience}

\section*{Experience's environnement}
In this part will be presented the environnement of the experimentations, on which hardware it was done, on which software, etc.
\subsection*{Hardware}
In this part, the hardware part of the computer will be explored. \newline
To explore the hardware of a computer on linux, the folder \texttt{/cpu} can be explored, it gives us the \textit{topology} of the cpu, like which threads are on each cores, which caches are on each cores, discover what is the cache line size etc...\newline
But there are also a lot of linux tools that allows to check the hardware's specifications of a computer, and basically doing the job for us. \newline
There are graphical tools such as \texttt{likwid}, which provides the command \texttt{likwid-topology}, or the tool \texttt{hwloc}, which provides \texttt{lstopo}, a command that gives a beautiful GUI of the computer's hardware's specification.
\begin{description}
    \item[Model name :] 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz
    \item[Adress size :] 39 bits physical, 48 bits virtual
    \item[Cache line size :] 64 bytes
    \item[Cores :] 4
\end{description}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \multicolumn{5}{|c|}{Graphical Topology} \\
        \hline
        Coeurs & \enspace0\enspace\enspace4 &\enspace1\enspace\enspace5 &\enspace2\enspace\enspace6 &\enspace3\enspace\enspace7 \\
        \hline
        Cache L1 & \enspace48 kB &\enspace48 kB &\enspace48 kB &\enspace48 kB \\
        \hline
        Cache L2 & 1MB & 1MB & 1MB & 1MB \\
        \hline
        Cache L3 & \multicolumn{4}{|c|}{8 MB} \\
        \hline
    \end{tabular}
    \caption{Computer's topology}
    \label{tab:graph_characteristics}
\end{table}


\subsection*{Software}
For the software part, the experiments were done on a lightweight configuration of the computer, where all unnecessary services were disabled, 
including the graphical interface, this allows the computer to run as baremetal as possible. \newline
Here is a description of all the software elements used in this benchmark :
\begin{description}
    \item[OS] Fedora Linux v40 WorkStation
    \item[gcc] version 14.2.1 20240912
    \item[icx] version 2024.2.1.20240711
    \item[clang] version 18.1.8
    \item[ccomp] version 3.14
\end{description}

\section{Method of experiment}
To compare the performance of the different compilers, two programs will be used, the first \texttt{matrix\_multiply}, is a \texttt{C} program 
that multiplies two matrices to put the result in a third matrix, it is an interesting challenge for optimization because of the presence of 3 nested loops for 
the calculation. This program will be compiled using \gcc, \clang, \icx and \comp. \newline
The second program is \texttt{dijkstra} algorithm using \texttt{C++}, the goal behind this is to compare the compilers optimizations when the program has a lot
of memory usage, because it is in \texttt{C++}, the program will only be compiled with the \texttt{C++} versions of \gcc, \clang and \icx, due to the lack of \texttt{C++}
compilation from \comp. \newline
Next, we can mesure time taken by the program by placing the c-function \texttt{gettimeofday()} around the function that we need to calculate, initialisation 
mesurement is not the main goal, but it can be mesured too. The programs are executed 12 times for each optimization level to make an interesting violin plot using \texttt{R}.

\section{Results}
\subsection{Matrix Multiply Results}
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{img/plots/violin_plot_mat_mult.png}
\caption{Evolution of the execution time of the program mat\_mult.c as a function of compiler and optimization level.}
\label{fig:image1}
\end{figure}
What we notice here is that \gcc gives the most optimized programs of them all, even by starting as the worst one, 
\comp is the worst one and can even notice that its execution times are really constant, the violin plots looks the same across all optimizations. \newline
\clang get really consistent maximum and minimum time across all optimizations from \optione to \optisize, but the violins are really differents one from another.
It doesn't offer great performances compared to \gcc, but it gives a good upgrade from \optizero, and is slightly better than \icx. \newline
\icx is the second worst compiler across the 4 that we analyze, its performances are even degrading with the optimizations levels.
%\clearpage
\subsection{Dijkstra Results}
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{img/plots/violin_plot_dijkstra.png}
\caption{Evolution of the execution time of the program dijkstra.cpp as a function of compiler and optimization level.}
\label{fig:image2}
\end{figure}
What we can notice from these 2 graphs, is how differently \gcc compares with \clang and \icx according to the language used, \texttt{C} or \texttt{C++}. 
When using \texttt{C}, \gcc produces way more optimized codes than \clang and \icx, whereas in \texttt{C++}, \gcc is the least performant one. \newline
Few experiments were done get some answers to why is it like this. \newline\newline
First, the experiments were made on the \texttt{C++} programs, at the compilation level of \optithree, this will give us some data to work with, and, 
by using the command \texttt{perf record} and \texttt{perf report}, we can use material performance counters to get a lot of data on the percentage of time used 
by a function, we could use profiling applications such as \texttt{gprof}, but \texttt{perf} allowed us to have more precise data and avoided us to recompile
entirely the program.\newline \newline
The results were the following:
\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
                           & \gcc    & \clang  & \icx   \\
\hline
total time taken & 136.37s       & 146.98s       & 155.65s \\
dijkstra usage   & $\approx26s$  & $\approx13s$  & $\approx17s$    \\
init/free usage  & $\approx109s$ & $\approx133s$ & $\approx138s$   \\
\hline
\end{tabular}
\end{table}
What we can get as results from here is that \gcc is the most optimized in terms of initialisation and memory management, but is the worst one in terms 
of pure dijkstra calculation. \newline
If we push further the analysis, we can see there are some points in the program where types inference were used, such as \texttt{for (auto edge : temp\_neighbors)}. 
\gcc might not be able to manage this type system as well as \clang or \icx, hence the lack of optimizations.

\clearpage
\part{Compilers}
In this part will be presented all the compilers used in this tutorship project, as well as deepening their optimization options for each optimizations levels.
\section{\gcc}
\gcc is the most popular \texttt{C} compiler, it comes in the \texttt{GNU Compiler Collection}, which includes compilers for \texttt{Fortran}, \texttt{C++}, \texttt{Go}...
\subsection{Optimization options}
\subsubsection{Method of obtention}
\gcc is really helpful regarding getting informations about what he does, because the compiler has an option for this sole purpose, which is
\begin{verbatim}
gcc --help=optimizers -Q -On
\end{verbatim}

\subsubsection{Options introduced by \optizero}
\gcc \optizero was originally meant to disable every optimization flags to give the least optimized code, however, the competition with other compilers led to 
now have some optimization flags enabled, 53 to be more precise. Not all optimizations will be presented, because the "optimizations" are for the most, analysis
options.
\newline
A part of the optimizations concerns loop optimizations, with the option \newline \texttt{-faggressive-loop-optimizations}, \gcc enables, as its name suggests, a lot of loop optimizations, 
such as \textbf{loop fusion} and \textbf{fission}, \textbf{loop unrolling}, \textbf{loop peeling}. \newline
Next is the dead code elimination, \gcc can also remove every line of code that isn't used, this doesn't impact the execution speed, but reduces the size of the generated code.\newline
And finally are the peephole optimizations this option introduces optimizations on a reduced window, optimizing redundant register moves, redundant calculations, etc.
\newline
Other enabled options at \optizero are either analysis options or add error-handling instructions.

\subsubsection{Options introduced by \optione}
\gcc \optione optimizations add optimizations to the tree that the compiler builds in the intermediate level.
\newline
First, there is the dead code and redundancy elimination, with the options \texttt{-ftree-dce}, \texttt{-ftree-fre} and \texttt{-ftree-dse}, \gcc removes all the \textbf{dead code}, computations that produce the same results as well as all \textbf{dead stores}, that means that the cpu has less operations to manage, and the code size is reduced.
\newline
Secondly, there is value and copy propagation, first, the option \texttt{-ftree-ccp} tells the compiler to propagate constant values across conditions when it's possible, it simplifies all the control flow and makes place for further optimizations, and can even help for \texttt{branch prediction}. \newline Secondly, the option \texttt{-ftree-copy-prop} propagates values with copy instructions, for example \texttt{b = a; c = b;} would be replaced with \texttt{c = a;}.
\newline
And finally, loop optimizations, there are two main options here to consider, the first, \texttt{-ftree-sink} moves computations outside of the loop when it's possible, it allows to avoid computing the same thing over and over. \newline
The second is \texttt{-ftree-sra} for \textit{scalar replacement of aggregates}, it breaks structures and array into individual variable when needed, it can improve register usage and enable even further optimizations. An example of this would be a variable of the struct \texttt{Point \{int x; int y\}} would be transformed from \texttt{Point p;} to \texttt{int p\_x, p\_y;}.
\newline
At \optione, there are also other options to enable inlining of functions, that means that a function call will be replaced by the function's body, which allows for further optimizations.


\subsubsection{Options introduced by \optitwo}
\gcc \optitwo introduces aligning of functions, jumps, labels, and loops, the aligning allows to ensures that the instructions fit at the beginning of cache lines, which can reduce cache misses. Also, aligning labels and jumps allows to decrease branch prediction misses.
\newline
\optitwo also enables \texttt{-funroll-loops}, which performs loop unrolling when iteration count is known, which allows the compiler to optimize as it wishes.


\subsubsection{Options introduced by \optithree}
\gcc \optithree enables also further loops optimizations, such as \texttt{loop peeling}, \texttt{loop jamming}, \texttt{loop unrolling}, \texttt{loop interchange}, \texttt{loop splitting}.
\begin{description}
\item[loop peeling] removes special cases in the loop and put them outside of the loop.
\item[loop jamming] combines two loops with the same scope/range into a single one, enabling more optimizations, and is generally combined with \texttt{loop unrolling}.
\item[loop interchange] swap two loops in a nested loop, this allows to put the most changing variable to the consecutive elements in memory, instead of 
having the most changing variable to the separate elements in memory, it's very useful in programs such as \texttt{matrix multiplication}.
\item[loop splitting] allows simplification of a loop by dividing it into several loops, it simplifies the loops with the pattern \textbf{for (int $i=0$; $i<10$; $i++$) 
if($i<5$)... else} into two loops, one with the range 0..4 and the other 5..9. It help in reducing dependencies.
\end{description}


\subsubsection{Options enabled by \optisize}
\gcc \optisize enables the same options as \gcc \optitwo, but removes the aligning optimizations to free some space.






\section{\icx}
It's Intel's compiler for their x86 architecture, it is made to deliver extremely optimized programs on their processor architecture.
\subsection{Optimization options}
\subsubsection{Method of obtention}
Everything is available in the online documentation, it's relatively easy to find what we need.
\subsubsection{Options introduced by \optizero}
Everything is disabled at \optizero.
\subsubsection{Options introduced by \optione}
At this level of optimization, \icx starts by introducing \textbf{data flow analysis}, to help gathering data about data flows throughout the whole program, 
allowing for optimizations.\newline
Then, the compiler can also reorganize code as he wishes with \textbf{code motion}, which allows to move non-changing result operations out of loop to avoid 
recomputing it over and over, and \textbf{instruction scheduling}, which allows to change the order of instructions, to hide memory latency for exemple, 
or doing something while something heavier is done. It is done to reduce CPU stall.
\newline\newline
Other optimizations are also enabled, \textbf{strength reduction}, that changes heavy operations for cheaper ones, like switching from a multiplication to a bit shift, \textbf{test replacement}, that simplifies loops' conditions for example : 
\begin{verbatim}
    if (x >= 0 && x < 100) { /* code */ } // base loop
    if ((unsigned)x < 100) { /* code */ } // optimized loop
\end{verbatim}
And, finally, \textbf{split-lifetime analysis}, can split the \textit{lifetime} of a variable into smaller lifetimes, to reallocate the registers when the variable is not used anymore.

\subsubsection{Options introduced by \optitwo}
At this level of optimization, \icx introduces more optimizations, like \textbf{constant propagation}, or \textbf{forward substitution}, which can replace variable with their expressions, for example : 
\begin{verbatim}
    int a = 5 + i
    int b = a + 3
\end{verbatim}
will be replaced by
\begin{verbatim}
    int b = 5 + i + 3
\end{verbatim}
These two options complete each other really well, because imagine that the variable \texttt{i} was a constant, it would be replaced by its value, hence further optimizing the program.\newline\newline
Additionnal optimizations are introduced, like \textbf{loop unrolling}, which reduces the number of iterations by executing multiple iterations within a single loop cycle,\textbf{peephole optimizations}, which examines small code fragments to identify and replace inefficiencies, such as redundant instructions or suboptimal sequences, improving code quality. Or even \textbf{optimized code selection}, replaces inefficient instructions or code sequences with more efficient alternatives.
\newline\newline
There are also code-removing optimizations such as \textbf{dead-code elimination}, \textbf{dead-store elimination}, and \textbf{dead static function elimination} which does not really improves performance but can help reduce the weight put on the CPU.

\subsubsection{Options introduced by \optithree}
It enables all the same optimizations as \optitwo but add more aggressive loop transformations such as \textbf{loop fusion}, \textbf{block-unroll-and-jam}, with these two options, the compiler expands and find the best fusions/jams in the loops and \textbf{collapsing-IF-statements}, where multiple successive if are combined into one to reduce branching therefore gaining performances.

















\section{\comp}
\textit{Certified Compiler}\newline
It's the only C compiler that is formally verified to produce a code described by the source code, optimized or not. By its formally verified nature, it is 
the one that produces the most inefficient code. It is generally used for safety critical programs where a bug introduced by compilation could lead to serious 
problems.
%In this part will be presented all the optimizations options that \comp enable at each optimization level, the only difference is that with this compiler, \optione, \optitwo and \optithree are all the same option, they enable the same optimizations. Moreover, \optizero enables nothing.

\subsection{Optimization options}
\subsubsection{Method of obtention}
Everything is available in the online documentation, it's relatively easy to find what we need.
\subsubsection{Options introduced by \optizero}
\comp doesn't enable anything at \optizero, and the main optimization level \texttt{-O} gives the same optimizations as \optione, \optitwo, \optithree, because they are just an alias of that optimization option.
\subsubsection{Options introduced by \optione,\optitwo,\optithree}
There are not a lot of options so here is a list of them

\begin{description}
    \item[-fcont-prop] enables constant propagation, a process that replaces variables with their known constant values throughout the program.
    \item[-fcse] activates the elimination of common subexpressions, reducing redundant calculations by reusing previously computed values.
    \item[-fif-conversion] with this option, the compiler decides whether to replace simple if-then-else statements or the conditional operator (?:) with conditional assignements.\newline
    The heuristic-based approach selectively optimizes small and balanced expressions, provided the target architecture supports a suitable conditional move instruction.
    \item[-finline]  enables or disables the inlining of functions, potentially improving performance by replacing function calls with the actual function code.
    \item[-finline-functions-called-once] specifically inlines functions that are called only once, reducing overhead while maintaining efficiency.
    \item[-fredundancy] activates the elimination of redundant computations and unnecessary memory stores, improving execution time by avoiding repetitive operations.
    \item[-ftailcalls] optimizes function calls in tail position, which can enhance performance by reusing the current function’s stack frame. 
    \item[-ffloat-const-prop 2] enables full propagation of floating-point constants, ensuring arithmetic is performed in IEEE double precision format with round-to-nearest mode.
\end{description}

\subsubsection{Options introduced by \optisize}
The documentation doesn't give a lot of informations about it. Just the usual "optimizes for code size".

\section{\clang}
It's a compiler made by the LLVM Developer Group, it can replace \gcc by supporting most of the option flags of \gcc. \newline
The objective behind this compiler is to create a compiler that allowed: first, better diagnostics, which allows to debug more easily, second, to be seperated from the GNU licence, which forced
softwares to be integrated to said licence and therefore having to open\-source proprietary software, third, to have a nimble compiler that is simple and easy to develop and maintain.
\subsection{Optimization options}
\subsubsection{Method of obtention}
\clang doesn't have a clear documentation about what it enables with each compilation level, however, it has 2 commands that can give what is enabled with each 
optimization level, there are 2 commands because of the way clang works. \newline
The compiler is divided in two parts, \clang, the part where the intermediate representation (IR) is made, and \texttt{opt}, the part that optimizes said IR. 
The first command is used to know which optimizations are enabled by \texttt{opt}.
\begin{verbatim}
llvm-as < /dev/null | opt -On -disable-output -debug-pass-manager
\end{verbatim}
The second command gives the optimizations added by \clang itself
\begin{verbatim}
diff -wy --suppress-common-lines \
    <(echo 'int;' | clang -xc - -o /dev/null -\#\#\# 2>&1 | tr " " "\n" | grep -v /tmp) \
    <(echo 'int;' | clang -xc -On - -o /dev/null -\#\#\# 2>&1 | tr " " "\n" | grep -v /tmp)
\end{verbatim}
\subsubsection{Options enabled at \optizero}
\clang like the other compilers doesn't enable a lot of optimizations, the optimizations are called \textbf{AlwaysInlinerPass}, which inlines functions marked
with the \texttt{always\_inline} attribute, \textbf{CoroConditionalWrapper}, which is related to coroutines support in C++, which is a function that can be 
paused and resumed, enabling asynchronous and cooperative task management. Finally, \textbf{VerifierPass} ensures that the LLVM Intermediate Representation 
generated by the compiler is correct and coherent with the original program.

\subsubsection{Options enabled at \optione, \optitwo, \optithree, \optisize}
Like for \comp, they enable all the same optimizations. 
\newline\newline
\clang introduces a lot of optimizations on the functions. \newline
It applies to functions the user-defined attributes such as \texttt{inline}, or automatically applies some attributes like \texttt{pure}, \texttt{const}, \texttt{noreturn}, etc. which will be helpful for other optimizations, such as inlining or dead code optimization. \newline
\clang also manipulate the functions arguments by removing \textit{"dead"} arguments, which simplifies function calls and memory usage. It also analyzes function calls to propagate information about the possible values of arguments or return values. This enables more precise optimizations, especially for indirect calls. \newline
It can also propagate function attributes (e.g., \texttt{noreturn}, \texttt{readonly}) through the call graph in reverse post-order, enabling interprocedural optimizations by analyzing functions and their dependencies. And, by analizing said call graph, it collects profiling information, which can be used to guide inlining or other optimizations.
\newline\newline
These optimization levels also introduces more common optimizations, the first is \textbf{ConstantMergePass}, which merges duplicate constant data, such as identical string literals or constant arrays, to save memory and reduce code size. The second one is \textbf{GlobalDCEPass} which removes unused global variables, functions, or other entities which reduces the size of the generated code. The last one is \textbf{GlobalOptPass}, which simplifies, removes, or transforms global constructs to improve runtime performance and reduce code size.


%https://clang.llvm.org/
%https://stackoverflow.com/questions/15548023/clang-optimization-levels

\clearpage
\nocite{*}
\bibliographystyle{plainnat}
\bibliography{bibliox}

\end{document}
